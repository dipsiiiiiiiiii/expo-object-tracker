import Foundation
import Vision
import AVFoundation
import UIKit
import CoreGraphics

class VideoProcessor {
    private var trackedObjects: [String: VNTrackingRequest] = [:]
    private var selectedObservations: [String: VNDetectedObjectObservation] = [:]
    
    func selectObject(videoUri: String, frameIndex: Int, boundingBox: [String: Double]) async throws -> String {
        guard let url = URL(string: videoUri) else {
            throw NSError(domain: "VideoProcessor", code: 1, userInfo: [NSLocalizedDescriptionKey: "Invalid video URI"])
        }
        
        let asset = AVAsset(url: url)
        let imageGenerator = AVAssetImageGenerator(asset: asset)
        imageGenerator.appliesPreferredTrackTransform = true
        
        let duration = try await asset.load(.duration)
        let frameTime = CMTime(seconds: Double(frameIndex) / 30.0, preferredTimescale: duration.timescale)
        
        let cgImage = try imageGenerator.copyCGImage(at: frameTime, actualTime: nil)
        
        guard let x = boundingBox["x"],
              let y = boundingBox["y"],
              let width = boundingBox["width"],
              let height = boundingBox["height"] else {
            throw NSError(domain: "VideoProcessor", code: 2, userInfo: [NSLocalizedDescriptionKey: "Invalid bounding box"])
        }
        
        // ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€
        print("ğŸ” SelectObject Debug:")
        print("   Input coordinates: x=\(x), y=\(y), width=\(width), height=\(height)")
        print("   Image size: \(cgImage.width)x\(cgImage.height)")
        
        // UIKit ì¢Œí‘œê³„ (ì™¼ìª½ ìƒë‹¨ 0,0)ë¥¼ Vision Framework ì¢Œí‘œê³„ (ì™¼ìª½ í•˜ë‹¨ 0,0)ë¡œ ë³€í™˜
        // Vision Frameworkì—ì„œ ì‹¤ì œë¡œ ê¸°ëŒ€í•˜ëŠ” ì¢Œí‘œê³„ë¥¼ ë§ì¶°ì¤˜ì•¼ í•¨
        let normalizedBoundingBox = CGRect(
            x: x / Double(cgImage.width),
            y: y / Double(cgImage.height),  // UIKit ì¢Œí‘œ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•´ë³´ê¸°
            width: width / Double(cgImage.width),
            height: height / Double(cgImage.height)
        )
        
        print("   Normalized bounding box: \(normalizedBoundingBox)")
        
        let observation = VNDetectedObjectObservation(boundingBox: normalizedBoundingBox)
        let objectId = UUID().uuidString
        
        selectedObservations[objectId] = observation
        
        return objectId
    }
    
    func generateObjectPreview(videoUri: String, objectId: String) async throws -> String {
        guard let url = URL(string: videoUri) else {
            throw NSError(domain: "VideoProcessor", code: 1, userInfo: [NSLocalizedDescriptionKey: "Invalid video URI"])
        }
        
        guard let observation = selectedObservations[objectId] else {
            throw NSError(domain: "VideoProcessor", code: 3, userInfo: [NSLocalizedDescriptionKey: "Object not found"])
        }
        
        let asset = AVAsset(url: url)
        let imageGenerator = AVAssetImageGenerator(asset: asset)
        imageGenerator.appliesPreferredTrackTransform = true
        imageGenerator.requestedTimeToleranceBefore = CMTime.zero
        imageGenerator.requestedTimeToleranceAfter = CMTime.zero
        
        // ë¹„ë””ì˜¤ íŠ¸ë™ì˜ ë³€í™˜ ì •ë³´ í™•ì¸
        guard let videoTrack = try await asset.loadTracks(withMediaType: .video).first else {
            throw NSError(domain: "VideoProcessor", code: 4, userInfo: [NSLocalizedDescriptionKey: "No video track found"])
        }
        
        let transform = try await videoTrack.load(.preferredTransform)
        print("ğŸ¬ Video transform: \(transform)")
        print("ğŸ¬ Natural size: \(try await videoTrack.load(.naturalSize))")
        
        let frameTime = CMTime(seconds: 0, preferredTimescale: 600)
        let cgImage = try imageGenerator.copyCGImage(at: frameTime, actualTime: nil)
        
        print("ğŸ–¼ï¸ Generated CGImage size: \(cgImage.width)x\(cgImage.height)")
        
        let ciImage = CIImage(cgImage: cgImage)
        let boundingBox = observation.boundingBox
        
        // ë””ë²„ê¹… ë¡œê·¸
        print("ğŸ¯ Debug Info:")
        print("   Original bounding box (normalized): \(boundingBox)")
        print("   Image size: \(ciImage.extent)")
        
        // ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë°”ìš´ë”© ë°•ìŠ¤ ë³€í™˜
        let imageWidth = ciImage.extent.width
        let imageHeight = ciImage.extent.height
        
        let context = CIContext()
        
        // CIImageë¥¼ CGImageë¡œ ë³€í™˜
        guard let outputCGImage = context.createCGImage(ciImage, from: ciImage.extent) else {
            throw NSError(domain: "VideoProcessor", code: 9, userInfo: [NSLocalizedDescriptionKey: "Failed to create CGImage"])
        }
        
        // Vision Framework ì •ê·œí™” ì¢Œí‘œë¥¼ UIKit í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜
        // ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ Vision Frameworkê°€ UIKitê³¼ ê°™ì€ ì¢Œí‘œê³„ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì„
        var uiKitBoundingBox = CGRect(
            x: boundingBox.origin.x * imageWidth,
            y: boundingBox.origin.y * imageHeight,  // ì¢Œí‘œ ë³€í™˜ ì—†ì´ ì§ì ‘ ì‚¬ìš©
            width: boundingBox.width * imageWidth,
            height: boundingBox.height * imageHeight
        )
        
        // ë¹„ë””ì˜¤ ë³€í™˜ì´ ì ìš©ëœ ê²½ìš° ë°”ìš´ë”© ë°•ìŠ¤ë„ í•¨ê»˜ ë³€í™˜
        if !transform.isIdentity {
            print("ğŸ”„ Applying transform to bounding box: \(transform)")
            // ë³€í™˜ ì ìš© - ì£¼ë¡œ íšŒì „ì´ë‚˜ ë’¤ì§‘ê¸°
            uiKitBoundingBox = uiKitBoundingBox.applying(transform)
            
            // ë³€í™˜ í›„ ìŒìˆ˜ ì¢Œí‘œë¥¼ ë³´ì •
            if uiKitBoundingBox.origin.x < 0 || uiKitBoundingBox.origin.y < 0 {
                let offsetX = max(0, -uiKitBoundingBox.origin.x)
                let offsetY = max(0, -uiKitBoundingBox.origin.y)
                uiKitBoundingBox = uiKitBoundingBox.offsetBy(dx: offsetX, dy: offsetY)
            }
        }
        
        print("   Vision normalized box: \(boundingBox)")
        print("   UIKit pixel box (final): \(uiKitBoundingBox)")
        print("   Transform applied: \(!transform.isIdentity)")
        
        print("   UIKit bounding box: \(uiKitBoundingBox)")
        
        let renderer = UIGraphicsImageRenderer(size: ciImage.extent.size)
        let resultUIImage = renderer.image { context in
            // ì›ë³¸ ì´ë¯¸ì§€ë¥¼ UIKit ì¢Œí‘œê³„ì— ë§ê²Œ ê·¸ë¦¬ê¸°
            let drawRect = CGRect(origin: .zero, size: ciImage.extent.size)
            
            // UIImageë¡œ ë³€í™˜í•´ì„œ ê·¸ë¦¬ë©´ ì¢Œí‘œê³„ê°€ ìë™ìœ¼ë¡œ ë§ì¶°ì§
            let uiImage = UIImage(cgImage: outputCGImage)
            uiImage.draw(in: drawRect)
            
            // ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (UIKit ì¢Œí‘œê³„ì—ì„œ)
            context.cgContext.setStrokeColor(UIColor.systemGreen.cgColor)
            context.cgContext.setLineWidth(4.0)
            context.cgContext.setLineDash(phase: 0, lengths: [10, 6])
            context.cgContext.stroke(uiKitBoundingBox)
            
            // ë°˜íˆ¬ëª… ì±„ìš°ê¸°
            context.cgContext.setFillColor(UIColor.systemGreen.withAlphaComponent(0.2).cgColor)
            context.cgContext.fill(uiKitBoundingBox)
            
            // ë¼ë²¨
            let labelText = "âœ“ Detected Object"
            let attributes: [NSAttributedString.Key: Any] = [
                .font: UIFont.boldSystemFont(ofSize: 16),
                .foregroundColor: UIColor.white
            ]
            
            let labelSize = labelText.size(withAttributes: attributes)
            let labelY = max(uiKitBoundingBox.origin.y - labelSize.height - 8, 8)
            let labelRect = CGRect(
                x: uiKitBoundingBox.origin.x,
                y: labelY,
                width: labelSize.width + 12,
                height: labelSize.height + 6
            )
            
            context.cgContext.setFillColor(UIColor.systemGreen.cgColor)
            context.cgContext.fill(labelRect)
            
            labelText.draw(at: CGPoint(x: labelRect.origin.x + 6, y: labelRect.origin.y + 3), withAttributes: attributes)
        }
        
        let resultImage = CIImage(image: resultUIImage) ?? ciImage
        
        // ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        let outputURL = FileManager.default.temporaryDirectory.appendingPathComponent("object_preview_\(UUID().uuidString).jpg")
        
        try context.writeJPEGRepresentation(of: resultImage, to: outputURL, colorSpace: resultImage.colorSpace ?? CGColorSpaceCreateDeviceRGB())
        
        return outputURL.absoluteString
    }
    
    func getVideoResolution(videoUri: String) async throws -> [String: Int] {
        guard let url = URL(string: videoUri) else {
            throw NSError(domain: "VideoProcessor", code: 1, userInfo: [NSLocalizedDescriptionKey: "Invalid video URI"])
        }
        
        let asset = AVAsset(url: url)
        guard let videoTrack = try await asset.loadTracks(withMediaType: .video).first else {
            throw NSError(domain: "VideoProcessor", code: 4, userInfo: [NSLocalizedDescriptionKey: "No video track found"])
        }
        
        let naturalSize = try await videoTrack.load(.naturalSize)
        let transform = try await videoTrack.load(.preferredTransform)
        
        // ë³€í™˜ì´ ì ìš©ëœ ì‹¤ì œ í‘œì‹œ í¬ê¸° ê³„ì‚°
        let size = naturalSize.applying(transform)
        let width = abs(Int(size.width))
        let height = abs(Int(size.height))
        
        return ["width": width, "height": height]
    }
    
    func trackObject(videoUri: String, objectId: String) async throws -> [[String: Any]] {
        guard let url = URL(string: videoUri) else {
            throw NSError(domain: "VideoProcessor", code: 1, userInfo: [NSLocalizedDescriptionKey: "Invalid video URI"])
        }
        
        guard let initialObservation = selectedObservations[objectId] else {
            throw NSError(domain: "VideoProcessor", code: 3, userInfo: [NSLocalizedDescriptionKey: "Object not found"])
        }
        
        let asset = AVAsset(url: url)
        let reader = try AVAssetReader(asset: asset)
        
        guard let videoTrack = try await asset.loadTracks(withMediaType: .video).first else {
            throw NSError(domain: "VideoProcessor", code: 4, userInfo: [NSLocalizedDescriptionKey: "No video track found"])
        }
        
        let output = AVAssetReaderTrackOutput(track: videoTrack, outputSettings: [
            kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA
        ])
        
        reader.add(output)
        reader.startReading()
        
        var trackingResults: [[String: Any]] = []
        var frameIndex = 0
        
        var trackingRequest = VNTrackObjectRequest(detectedObjectObservation: initialObservation)
        trackingRequest.trackingLevel = .accurate
        
        while let sampleBuffer = output.copyNextSampleBuffer() {
            guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else {
                continue
            }
            
            let requestHandler = VNImageRequestHandler(cvPixelBuffer: pixelBuffer)
            
            do {
                try requestHandler.perform([trackingRequest])
                
                if let observation = trackingRequest.results?.first as? VNDetectedObjectObservation {
                    let boundingBox = observation.boundingBox
                    
                    let trackingData: [String: Any] = [
                        "frameIndex": frameIndex,
                        "boundingBox": [
                            "x": boundingBox.origin.x,
                            "y": 1.0 - boundingBox.origin.y - boundingBox.height,
                            "width": boundingBox.width,
                            "height": boundingBox.height
                        ],
                        "confidence": observation.confidence
                    ]
                    
                    trackingResults.append(trackingData)
                    
                    let nextRequest = VNTrackObjectRequest(detectedObjectObservation: observation)
                    nextRequest.trackingLevel = .accurate
                    trackingRequest = nextRequest
                }
            } catch {
                print("Tracking failed for frame \(frameIndex): \(error)")
                break
            }
            
            frameIndex += 1
        }
        
        reader.cancelReading()
        return trackingResults
    }
    
    func applyEffectToTrackedObject(videoUri: String, trackingData: [[String: Any]], effectConfig: [String: Any]) async throws -> String {
        guard let url = URL(string: videoUri) else {
            throw NSError(domain: "VideoProcessor", code: 1, userInfo: [NSLocalizedDescriptionKey: "Invalid video URI"])
        }
        
        let asset = AVAsset(url: url)
        let composition = AVMutableComposition()
        
        guard let videoTrack = try await asset.loadTracks(withMediaType: .video).first else {
            throw NSError(domain: "VideoProcessor", code: 4, userInfo: [NSLocalizedDescriptionKey: "No video track found"])
        }
        
        guard let compositionVideoTrack = composition.addMutableTrack(withMediaType: .video, preferredTrackID: kCMPersistentTrackID_Invalid) else {
            throw NSError(domain: "VideoProcessor", code: 7, userInfo: [NSLocalizedDescriptionKey: "Failed to create composition video track"])
        }
        
        let timeRange = try await videoTrack.load(.timeRange)
        try compositionVideoTrack.insertTimeRange(timeRange, of: videoTrack, at: CMTime.zero)
        
        let videoComposition = AVMutableVideoComposition()
        videoComposition.frameDuration = CMTime(value: 1, timescale: 30)
        videoComposition.renderSize = try await videoTrack.load(.naturalSize)
        
        let instruction = AVMutableVideoCompositionInstruction()
        instruction.timeRange = timeRange
        
        let layerInstruction = AVMutableVideoCompositionLayerInstruction(assetTrack: compositionVideoTrack)
        instruction.layerInstructions = [layerInstruction]
        
        videoComposition.instructions = [instruction]
        
        // íš¨ê³¼ íŒ©í† ë¦¬ì—ì„œ íš¨ê³¼ ìƒì„±
        guard let effect = EffectFactory.createEffect(from: effectConfig) else {
            throw NSError(domain: "VideoProcessor", code: 8, userInfo: [NSLocalizedDescriptionKey: "Invalid effect configuration"])
        }
        
        // TODO: Core Imageë¥¼ ì‚¬ìš©í•œ ì‹¤ì œ íš¨ê³¼ ì ìš© ë¡œì§ êµ¬í˜„
        // í˜„ì¬ëŠ” ê¸°ë³¸ ë¹„ë””ì˜¤ë§Œ ì¶œë ¥
        
        let outputURL = FileManager.default.temporaryDirectory.appendingPathComponent("processed_video_\(UUID().uuidString).mp4")
        
        guard let exportSession = AVAssetExportSession(asset: composition, presetName: AVAssetExportPresetHighestQuality) else {
            throw NSError(domain: "VideoProcessor", code: 5, userInfo: [NSLocalizedDescriptionKey: "Failed to create export session"])
        }
        
        exportSession.outputURL = outputURL
        exportSession.outputFileType = .mp4
        exportSession.videoComposition = videoComposition
        
        await exportSession.export()
        
        guard exportSession.status == .completed else {
            throw NSError(domain: "VideoProcessor", code: 6, userInfo: [NSLocalizedDescriptionKey: "Export failed: \(exportSession.error?.localizedDescription ?? "Unknown error")"])
        }
        
        return outputURL.absoluteString
    }
    
    func generatePreviewFrames(videoUri: String, trackingData: [[String: Any]], frameCount: Int) async throws -> [[String: Any]] {
        guard let url = URL(string: videoUri) else {
            throw NSError(domain: "VideoProcessor", code: 1, userInfo: [NSLocalizedDescriptionKey: "Invalid video URI"])
        }
        
        let asset = AVAsset(url: url)
        let imageGenerator = AVAssetImageGenerator(asset: asset)
        imageGenerator.appliesPreferredTrackTransform = true
        
        let duration = try await asset.load(.duration)
        let totalFrames = trackingData.count
        let step = max(1, totalFrames / frameCount)
        
        var previewFrames: [[String: Any]] = []
        
        for i in stride(from: 0, to: totalFrames, by: step) {
            if previewFrames.count >= frameCount { break }
            
            guard let trackingInfo = trackingData.first(where: { data in
                if let frameIndex = data["frameIndex"] as? Int {
                    return frameIndex == i
                }
                return false
            }) else { continue }
            
            let time = CMTime(seconds: Double(i) / 30.0, preferredTimescale: duration.timescale)
            
            do {
                let cgImage = try imageGenerator.copyCGImage(at: time, actualTime: nil)
                
                // ì´ë¯¸ì§€ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                let tempURL = FileManager.default.temporaryDirectory.appendingPathComponent("preview_frame_\(i)_\(UUID().uuidString).jpg")
                
                let ciImage = CIImage(cgImage: cgImage)
                let context = CIContext()
                try context.writeJPEGRepresentation(of: ciImage, to: tempURL, colorSpace: ciImage.colorSpace ?? CGColorSpaceCreateDeviceRGB())
                
                let previewFrame: [String: Any] = [
                    "frameIndex": i,
                    "imageUri": tempURL.absoluteString,
                    "boundingBox": trackingInfo["boundingBox"] ?? [:]
                ]
                
                previewFrames.append(previewFrame)
            } catch {
                print("Failed to generate preview frame at index \(i): \(error)")
                continue
            }
        }
        
        return previewFrames
    }
    
    func applyEffectToFrame(frameUri: String, boundingBox: [String: Any], effectConfig: [String: Any]) async throws -> String {
        guard let url = URL(string: frameUri) else {
            throw NSError(domain: "VideoProcessor", code: 1, userInfo: [NSLocalizedDescriptionKey: "Invalid frame URI"])
        }
        
        guard let effect = EffectFactory.createEffect(from: effectConfig) else {
            throw NSError(domain: "VideoProcessor", code: 8, userInfo: [NSLocalizedDescriptionKey: "Invalid effect configuration"])
        }
        
        guard let x = boundingBox["x"] as? Double,
              let y = boundingBox["y"] as? Double,
              let width = boundingBox["width"] as? Double,
              let height = boundingBox["height"] as? Double else {
            throw NSError(domain: "VideoProcessor", code: 2, userInfo: [NSLocalizedDescriptionKey: "Invalid bounding box"])
        }
        
        let ciImage = CIImage(contentsOf: url)!
        let boundingRect = CGRect(x: x * ciImage.extent.width, y: y * ciImage.extent.height, 
                                width: width * ciImage.extent.width, height: height * ciImage.extent.height)
        
        let processedImage = effect.apply(to: ciImage, boundingBox: boundingRect)
        
        // ì²˜ë¦¬ëœ ì´ë¯¸ì§€ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        let outputURL = FileManager.default.temporaryDirectory.appendingPathComponent("processed_frame_\(UUID().uuidString).jpg")
        
        let context = CIContext()
        try context.writeJPEGRepresentation(of: processedImage, to: outputURL, colorSpace: processedImage.colorSpace ?? CGColorSpaceCreateDeviceRGB())
        
        return outputURL.absoluteString
    }
}