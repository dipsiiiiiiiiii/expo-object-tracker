import React, { useState, useEffect } from "react";
import {
  Alert,
  Button,
  SafeAreaView,
  ScrollView,
  Text,
  View,
  StyleSheet,
  Image as RNImage,
  Dimensions,
  TouchableOpacity,
} from "react-native";
import * as DocumentPicker from "expo-document-picker";
import * as FileSystem from "expo-file-system";
import * as VideoThumbnails from "expo-video-thumbnails";
import { Asset } from "expo-asset";
import ExpoObjectTracker, {
  BoundingBox,
  TrackingData,
  EffectConfig,
  PreviewFrame,
  VideoObjectTrackerClass,
  SAMSegmentationResult,
} from "expo-object-tracker";

import SAMObjectSelector from "./SAMObjectSelector";

export default function App() {
  const [videoUri, setVideoUri] = useState<string>("");
  const [thumbnailUri, setThumbnailUri] = useState<string>("");
  const [segmentationResult, setSegmentationResult] = 
    useState<SAMSegmentationResult | null>(null);
  const [selectedPoint, setSelectedPoint] = 
    useState<{x: number, y: number} | null>(null);
  const [processedVideoUri, setProcessedVideoUri] = useState<string>("");
  const [status, setStatus] = useState<string>("Initializing...");
  const [showSAMSelector, setShowSAMSelector] = useState<boolean>(false);
  const [videoResolution, setVideoResolution] = useState<{
    width: number;
    height: number;
  } | null>(null);
  const [modelLoaded, setModelLoaded] = useState<boolean>(false);

  // Create VideoObjectTracker instance
  const videoObjectTracker = new VideoObjectTrackerClass();

  const { width: screenWidth } = Dimensions.get("window");
  const thumbnailWidth = screenWidth - 40;
  const thumbnailHeight = (thumbnailWidth * 9) / 16; // 16:9 ë¹„ìœ¨

  // ì•± ì‹œì‘ ì‹œ ëª¨ë¸ ë¡œë“œ (SAM ëª¨ë¸ì€ ëª¨ë“ˆì— ë‚´ì¥ë¨)
  useEffect(() => {
    const initializeApp = async () => {
      try {
        setStatus("Initializing SAM model...");
        
        // SAM ëª¨ë¸ì€ iOS ëª¨ë“ˆì— ë‚´ì¥ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ë³„ë„ ë¡œë“œ ë¶ˆí•„ìš”
        // í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ê°„ë‹¨í•œ ì´ˆê¸°í™”ë§Œ ìˆ˜í–‰
        await new Promise(resolve => setTimeout(resolve, 1000));
        
        setModelLoaded(true);
        setStatus("Ready - SAM model initialized");
        console.log("SAM model ready");
      } catch (error) {
        console.error("Failed to initialize SAM model:", error);
        setStatus("Failed to initialize SAM model");
        Alert.alert("Error", "Failed to initialize SAM model.");
      }
    };
    
    initializeApp();
  }, []);

  // ë¹„ë””ì˜¤ ì„ íƒ
  const selectVideo = async () => {
    try {
      const result = await DocumentPicker.getDocumentAsync({
        type: "video/*",
        copyToCacheDirectory: true,
      });

      if (result.assets && result.assets.length > 0) {
        const uri = result.assets[0].uri;
        await loadVideo(uri);
      }
    } catch (error) {
      setStatus("Video selection failed");
      Alert.alert("Error", "Failed to select video");
      console.error("Video selection error:", error);
    }
  };

  // í…ŒìŠ¤íŠ¸ ë¹„ë””ì˜¤ ë¡œë“œ
  const loadTestVideo = async () => {
    try {
      setStatus("Loading test video...");

      // assetsì—ì„œ test-video.mp4 ë¡œë“œ
      const asset = Asset.fromModule(require("./assets/test-video.mp4"));
      await asset.downloadAsync();

      await loadVideo(asset.localUri || asset.uri);
    } catch (error) {
      setStatus("Test video loading failed");
      Alert.alert("Error", "Failed to load test video");
      console.error("Test video loading error:", error);
    }
  };

  // ê³µí†µ ë¹„ë””ì˜¤ ë¡œë”© ë¡œì§
  const loadVideo = async (uri: string) => {
    try {
      setVideoUri(uri);
      setStatus("Generating thumbnail...");

      // ì¸ë„¤ì¼ ìƒì„±
      const { uri: thumbnail } = await VideoThumbnails.getThumbnailAsync(uri, {
        time: 0,
        quality: 0.8,
      });

      setThumbnailUri(thumbnail);

      // ë¹„ë””ì˜¤ í•´ìƒë„ ê°€ì ¸ì˜¤ê¸°
      const resolution = await videoObjectTracker.getVideoResolution(uri);
      setVideoResolution(resolution);
      console.log("Video resolution:", resolution);

      setStatus("Video loaded - Ready to select object");
      console.log("Video loaded:", uri);
      console.log("Thumbnail:", thumbnail);

      // ì´ì „ ê²°ê³¼ë“¤ ì´ˆê¸°í™”
      setSegmentationResult(null);
      setSelectedPoint(null);
      setProcessedVideoUri("");
    } catch (error) {
      setStatus("Video processing failed");
      Alert.alert("Error", "Failed to process video");
      console.error("Video processing error:", error);
    }
  };

  // SAM ê°ì²´ ì„ íƒ í™”ë©´ í‘œì‹œ
  const showSAMObjectSelection = () => {
    if (!thumbnailUri) {
      Alert.alert("Error", "Please select a video first");
      return;
    }
    setShowSAMSelector(true);
  };

  // SAM ì„¸ê·¸ë¨¼í…Œì´ì…˜ ì™„ë£Œ ì½œë°±
  const onObjectSegmented = (result: SAMSegmentationResult, point: {x: number, y: number}) => {
    setSegmentationResult(result);
    setSelectedPoint(point);
    setShowSAMSelector(false);
    setStatus(`Object segmented with ${Math.round(result.confidence * 100)}% confidence`);
    console.log("SAM Segmentation Result:", result);
    console.log("Selected Point:", point);
  };

  // íš¨ê³¼ ì ìš©í•˜ê¸°
  const applyEffectToSegmentation = async () => {
    if (!segmentationResult) {
      Alert.alert("Error", "No segmentation result available");
      return;
    }

    try {
      setStatus("Applying effect to segmented object...");
      
      // ì—¬ê¸°ì„œ ì‹¤ì œ íš¨ê³¼ ì ìš© ë¡œì§ êµ¬í˜„
      // í˜„ì¬ëŠ” placeholder
      console.log("Applying effect with mask:", segmentationResult.maskUri);
      
      // ì„ì‹œë¡œ ì„±ê³µ ë©”ì‹œì§€
      await new Promise(resolve => setTimeout(resolve, 1000));
      setStatus("Effect applied successfully!");
      Alert.alert("Success", "Effect applied to the segmented object!");
      
    } catch (error) {
      setStatus("Failed to apply effect");
      Alert.alert("Error", "Failed to apply effect: " + error);
    }
  };

  // ê°ì²´ ì¶”ì 
  const trackObject = async () => {
    if (!objectId) {
      Alert.alert("Error", "Please select object first");
      return;
    }

    try {
      setStatus("Tracking object...");

      const results = await ExpoObjectTracker.trackObject(videoUri, objectId);
      setTrackingResults(results);
      setStatus(`Tracking completed - ${results.length} frames`);

      // ë¯¸ë¦¬ë³´ê¸° í”„ë ˆì„ ìƒì„± (5ê°œ í”„ë ˆì„)
      setStatus("Generating preview frames...");
      const frames = await ExpoObjectTracker.generatePreviewFrames(
        videoUri,
        results,
        5
      );
      setPreviewFrames(frames);

      setStatus(`Tracking completed - Ready for effects preview`);
      Alert.alert("Success", `Tracked object in ${results.length} frames`);
      console.log("Tracking results:", results.slice(0, 5)); // ì²« 5í”„ë ˆì„ë§Œ ë¡œê·¸
    } catch (error) {
      setStatus("Tracking failed");
      Alert.alert("Error", "Failed to track object: " + error);
      console.error("Object tracking error:", error);
    }
  };

  // íš¨ê³¼ ë¯¸ë¦¬ë³´ê¸°
  const previewEffect = async (
    effectConfig: EffectConfig,
    effectName: string
  ) => {
    if (previewFrames.length === 0) {
      Alert.alert("Error", "Please track object first");
      return;
    }

    try {
      setStatus(`Generating ${effectName} preview...`);
      setCurrentPreviewEffect(effectConfig);

      const newPreviewImages: { [key: string]: string } = {};

      // ê° ë¯¸ë¦¬ë³´ê¸° í”„ë ˆì„ì— íš¨ê³¼ ì ìš©
      for (const frame of previewFrames) {
        const processedUri = await ExpoObjectTracker.applyEffectToFrame(
          frame.imageUri,
          frame.boundingBox,
          effectConfig
        );
        newPreviewImages[`${effectName}-${frame.frameIndex}`] = processedUri;
      }

      setPreviewImages(newPreviewImages);
      setStatus(`${effectName} preview ready`);
    } catch (error) {
      setStatus("Preview generation failed");
      Alert.alert(
        "Error",
        `Failed to generate ${effectName} preview: ` + error
      );
      console.error("Preview generation error:", error);
    }
  };

  // ìµœì¢… ë¹„ë””ì˜¤ ì €ì¥
  const saveVideo = async () => {
    if (!currentPreviewEffect || trackingResults.length === 0) {
      Alert.alert("Error", "Please preview an effect first");
      return;
    }

    try {
      setStatus("Saving video with effects...");

      const processedUri = await ExpoObjectTracker.applyEffectToTrackedObject(
        videoUri,
        trackingResults,
        currentPreviewEffect
      );

      setProcessedVideoUri(processedUri);
      setStatus("Video saved successfully");

      Alert.alert("Success", `Video saved at: ${processedUri}`);
      console.log("Processed video URI:", processedUri);
    } catch (error) {
      setStatus("Video save failed");
      Alert.alert("Error", "Failed to save video: " + error);
      console.error("Video save error:", error);
    }
  };

  // ê° íš¨ê³¼ë³„ ë¯¸ë¦¬ë³´ê¸° í•¸ë“¤ëŸ¬ë“¤
  const previewBlurEffect = () =>
    previewEffect({ type: "blur", intensity: 8 }, "blur");
  const previewMosaicEffect = () =>
    previewEffect({ type: "mosaic", blockSize: 15 }, "mosaic");
  const previewEmojiEffect = () =>
    previewEffect({ type: "emoji", emoji: "ğŸ˜", scale: 1.5 }, "emoji");
  const previewColorEffect = () =>
    previewEffect({ type: "color", color: "#FF0000", opacity: 0.7 }, "color");

  // SAM ê°ì²´ ì„ íƒê¸° í‘œì‹œ
  if (showSAMSelector && thumbnailUri) {
    return (
      <SafeAreaView style={styles.container}>
        <SAMObjectSelector
          thumbnailUri={thumbnailUri}
          videoUri={videoUri}
          imageWidth={thumbnailWidth}
          imageHeight={thumbnailHeight}
          onObjectSegmented={onObjectSegmented}
          onCancel={() => setShowSAMSelector(false)}
        />
      </SafeAreaView>
    );
  }

  return (
    <SafeAreaView style={styles.container}>
      <ScrollView style={styles.container}>
        <Text style={styles.header}>ğŸ¤– AI ê°ì²´ ì„¸ê·¸ë¨¼í…Œì´ì…˜ & ë¸”ëŸ¬</Text>

        <Group name="Status">
          <Text style={styles.statusText}>{status}</Text>
        </Group>

        <Group name="1. ë¹„ë””ì˜¤ ì„ íƒ">
          <View style={styles.effectButtonsContainer}>
            <Button 
              title="ê°¤ëŸ¬ë¦¬ì—ì„œ ì„ íƒ" 
              onPress={selectVideo} 
              disabled={!modelLoaded}
            />
            <Button 
              title="í…ŒìŠ¤íŠ¸ ë¹„ë””ì˜¤ ì‚¬ìš©" 
              onPress={loadTestVideo} 
              disabled={!modelLoaded}
            />
          </View>
          {!modelLoaded ? (
            <Text style={styles.infoText}>SAM ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...</Text>
          ) : videoUri ? (
            <Text style={styles.infoText}>âœ… ë¹„ë””ì˜¤ ë¡œë“œë¨</Text>
          ) : null}
        </Group>

        <Group name="2. AI ê°ì²´ ì„ íƒ">
          <Button
            title="ğŸ¯ ê°ì²´ í„°ì¹˜í•´ì„œ ì„ íƒí•˜ê¸°"
            onPress={showSAMObjectSelection}
            disabled={!thumbnailUri}
          />
          <Text style={styles.hintText}>
            ğŸ’¡ Segment Anything AIê°€ í„°ì¹˜í•œ ê°ì²´ë¥¼ ì •ë°€í•˜ê²Œ ì°¾ìŠµë‹ˆë‹¤
          </Text>
          
          {segmentationResult ? (
            <View>
              <Text style={styles.infoText}>âœ… ê°ì²´ ì„¸ê·¸ë¨¼í…Œì´ì…˜ ì™„ë£Œ!</Text>
              <Text style={styles.resultText}>
                ì‹ ë¢°ë„: {Math.round(segmentationResult.confidence * 100)}%
              </Text>
              <Text style={styles.resultText}>
                ì„ íƒëœ ìœ„ì¹˜: ({selectedPoint?.x.toFixed(0)}, {selectedPoint?.y.toFixed(0)})
              </Text>
            </View>
          ) : null}
        </Group>

        {segmentationResult && (
          <Group name="3. íš¨ê³¼ ì ìš©">
            <View style={styles.effectButtonsContainer}>
              <Button
                title="ğŸŒ€ ë¸”ëŸ¬ íš¨ê³¼"
                onPress={applyEffectToSegmentation}
              />
              <Button
                title="ğŸ”³ ëª¨ìì´í¬"
                onPress={applyEffectToSegmentation}
              />
            </View>
            <Text style={styles.hintText}>
              ì„ íƒëœ ê°ì²´ ì˜ì—­ì—ë§Œ íš¨ê³¼ê°€ ì •ë°€í•˜ê²Œ ì ìš©ë©ë‹ˆë‹¤
            </Text>
          </Group>
        )}

        {processedVideoUri && (
          <Group name="ê²°ê³¼">
            <Text style={styles.infoText}>âœ… íš¨ê³¼ ì ìš© ì™„ë£Œ!</Text>
            <Text style={styles.resultText}>
              ì²˜ë¦¬ëœ ë¹„ë””ì˜¤: {processedVideoUri}
            </Text>
          </Group>
        )}
      </ScrollView>
    </SafeAreaView>
  );
}

function Group(props: { name: string; children: React.ReactNode }) {
  return (
    <View style={styles.group}>
      <Text style={styles.groupHeader}>{props.name}</Text>
      {props.children}
    </View>
  );
}

const styles = StyleSheet.create({
  header: {
    fontSize: 24,
    fontWeight: "bold" as const,
    margin: 20,
    textAlign: "center" as const,
    color: "#333",
  },
  groupHeader: {
    fontSize: 18,
    fontWeight: "bold" as const,
    marginBottom: 15,
    color: "#444",
  },
  group: {
    margin: 15,
    backgroundColor: "#fff",
    borderRadius: 12,
    padding: 20,
    shadowColor: "#000",
    shadowOffset: { width: 0, height: 2 },
    shadowOpacity: 0.1,
    shadowRadius: 4,
    elevation: 3,
  },
  container: {
    flex: 1,
    backgroundColor: "#f5f5f5",
  },
  statusText: {
    fontSize: 16,
    fontWeight: "500" as const,
    color: "#007AFF",
    textAlign: "center" as const,
  },
  infoText: {
    fontSize: 14,
    color: "#28a745",
    marginTop: 10,
    textAlign: "center" as const,
  },
  resultText: {
    fontSize: 12,
    color: "#666",
    marginTop: 5,
  },
  selectorContainer: {
    flex: 1,
    padding: 20,
    alignItems: "center" as const,
  },
  instructionText: {
    fontSize: 16,
    color: "#666",
    textAlign: "center" as const,
    marginBottom: 20,
  },
  buttonContainer: {
    marginTop: 20,
    width: "100%",
  },
  effectButtonsContainer: {
    flexDirection: "row" as const,
    justifyContent: "space-around",
    marginBottom: 10,
  },
  previewContainer: {
    marginTop: 15,
    padding: 10,
    backgroundColor: "#f8f8f8",
    borderRadius: 8,
  },
  previewTitle: {
    fontSize: 14,
    fontWeight: "600" as const,
    marginBottom: 10,
    color: "#333",
  },
  previewImage: {
    width: 120,
    height: 90,
    marginRight: 10,
    borderRadius: 6,
    borderWidth: 1,
    borderColor: "#ddd",
  },
  previewImageContainer: {
    marginBottom: 20,
    borderRadius: 8,
    overflow: "hidden",
    borderWidth: 2,
    borderColor: "#4CAF50",
  },
  detectionInfo: {
    backgroundColor: "white",
    padding: 15,
    borderRadius: 8,
    marginBottom: 20,
    alignItems: "center" as const,
    shadowColor: "#000",
    shadowOffset: { width: 0, height: 1 },
    shadowOpacity: 0.2,
    shadowRadius: 2,
    elevation: 2,
  },
  detectionText: {
    fontSize: 14,
    color: "#333",
    marginBottom: 5,
    fontWeight: "500" as const,
  },
  confirmButtonContainer: {
    flexDirection: "row" as const,
    justifyContent: "space-around",
    width: "100%",
    maxWidth: 300,
  },
  retryButton: {
    backgroundColor: "#FF9800",
  },
  button: {
    paddingVertical: 12,
    paddingHorizontal: 20,
    borderRadius: 8,
    minWidth: 80,
    alignItems: "center" as const,
    margin: 5,
  },
  buttonText: {
    color: "white",
    fontSize: 16,
    fontWeight: "600" as const,
  },
  confirmButton: {
    backgroundColor: "#4CAF50",
  },
  hintText: {
    fontSize: 12,
    color: "#6c757d",
    textAlign: "center" as const,
    marginTop: 8,
    fontStyle: "italic" as const,
  },
});
