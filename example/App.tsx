import React, { useState, useEffect } from "react";
import {
  Alert,
  Button,
  SafeAreaView,
  ScrollView,
  Text,
  View,
  StyleSheet,
  Image as RNImage,
  Dimensions,
  TouchableOpacity,
} from "react-native";
import * as DocumentPicker from "expo-document-picker";
import * as FileSystem from "expo-file-system";
import * as VideoThumbnails from "expo-video-thumbnails";
import { Asset } from "expo-asset";
import ExpoObjectTracker, {
  BoundingBox,
  TrackingData,
  EffectConfig,
  PreviewFrame,
  VideoObjectTrackerClass,
  SAMSegmentationResult,
} from "expo-object-tracker";

import SAMObjectSelector from "./SAMObjectSelector";

export default function App() {
  const [videoUri, setVideoUri] = useState<string>("");
  const [thumbnailUri, setThumbnailUri] = useState<string>("");
  const [segmentationResult, setSegmentationResult] = 
    useState<SAMSegmentationResult | null>(null);
  const [selectedPoint, setSelectedPoint] = 
    useState<{x: number, y: number} | null>(null);
  const [processedVideoUri, setProcessedVideoUri] = useState<string>("");
  const [status, setStatus] = useState<string>("Initializing...");
  const [showSAMSelector, setShowSAMSelector] = useState<boolean>(false);
  const [videoResolution, setVideoResolution] = useState<{
    width: number;
    height: number;
  } | null>(null);
  const [modelLoaded, setModelLoaded] = useState<boolean>(false);

  // Create VideoObjectTracker instance
  const videoObjectTracker = new VideoObjectTrackerClass();

  const { width: screenWidth } = Dimensions.get("window");
  const thumbnailWidth = screenWidth - 40;
  const thumbnailHeight = (thumbnailWidth * 9) / 16; // 16:9 ÎπÑÏú®

  // Ïï± ÏãúÏûë Ïãú Î™®Îç∏ Î°úÎìú (SAM Î™®Îç∏ÏùÄ Î™®ÎìàÏóê ÎÇ¥Ïû•Îê®)
  useEffect(() => {
    const initializeApp = async () => {
      try {
        setStatus("Initializing SAM model...");
        
        // SAM Î™®Îç∏ÏùÄ iOS Î™®ÎìàÏóê ÎÇ¥Ïû•ÎêòÏñ¥ ÏûàÏúºÎØÄÎ°ú Î≥ÑÎèÑ Î°úÎìú Î∂àÌïÑÏöî
        // ÌÖåÏä§Ìä∏Ïö©ÏúºÎ°ú Í∞ÑÎã®Ìïú Ï¥àÍ∏∞ÌôîÎßå ÏàòÌñâ
        await new Promise(resolve => setTimeout(resolve, 1000));
        
        setModelLoaded(true);
        setStatus("Ready - SAM model initialized");
        console.log("SAM model ready");
      } catch (error) {
        console.error("Failed to initialize SAM model:", error);
        setStatus("Failed to initialize SAM model");
        Alert.alert("Error", "Failed to initialize SAM model.");
      }
    };
    
    initializeApp();
  }, []);

  // ÎπÑÎîîÏò§ ÏÑ†ÌÉù
  const selectVideo = async () => {
    try {
      const result = await DocumentPicker.getDocumentAsync({
        type: "video/*",
        copyToCacheDirectory: true,
      });

      if (result.assets && result.assets.length > 0) {
        const uri = result.assets[0].uri;
        await loadVideo(uri);
      }
    } catch (error) {
      setStatus("Video selection failed");
      Alert.alert("Error", "Failed to select video");
      console.error("Video selection error:", error);
    }
  };

  // ÌÖåÏä§Ìä∏ ÎπÑÎîîÏò§ Î°úÎìú
  const loadTestVideo = async () => {
    try {
      setStatus("Loading test video...");

      // assetsÏóêÏÑú test-video.mp4 Î°úÎìú
      const asset = Asset.fromModule(require("./assets/test-video.mp4"));
      await asset.downloadAsync();

      await loadVideo(asset.localUri || asset.uri);
    } catch (error) {
      setStatus("Test video loading failed");
      Alert.alert("Error", "Failed to load test video");
      console.error("Test video loading error:", error);
    }
  };

  // Í≥µÌÜµ ÎπÑÎîîÏò§ Î°úÎî© Î°úÏßÅ
  const loadVideo = async (uri: string) => {
    try {
      setVideoUri(uri);
      setStatus("Generating thumbnail...");

      // Ïç∏ÎÑ§Ïùº ÏÉùÏÑ±
      const { uri: thumbnail } = await VideoThumbnails.getThumbnailAsync(uri, {
        time: 0,
        quality: 0.8,
      });

      setThumbnailUri(thumbnail);

      // ÎπÑÎîîÏò§ Ìï¥ÏÉÅÎèÑ Í∞ÄÏ†∏Ïò§Í∏∞
      const resolution = await videoObjectTracker.getVideoResolution(uri);
      setVideoResolution(resolution);
      console.log("Video resolution:", resolution);

      setStatus("Video loaded - Ready to select object");
      console.log("Video loaded:", uri);
      console.log("Thumbnail:", thumbnail);

      // Ïù¥Ï†Ñ Í≤∞Í≥ºÎì§ Ï¥àÍ∏∞Ìôî
      setSegmentationResult(null);
      setSelectedPoint(null);
      setProcessedVideoUri("");
    } catch (error) {
      setStatus("Video processing failed");
      Alert.alert("Error", "Failed to process video");
      console.error("Video processing error:", error);
    }
  };

  // SAM Í∞ùÏ≤¥ ÏÑ†ÌÉù ÌôîÎ©¥ ÌëúÏãú
  const showSAMObjectSelection = () => {
    if (!thumbnailUri) {
      Alert.alert("Error", "Please select a video first");
      return;
    }
    setShowSAMSelector(true);
  };

  // SAM ÏÑ∏Í∑∏Î®ºÌÖåÏù¥ÏÖò ÏôÑÎ£å ÏΩúÎ∞±
  const onObjectSegmented = (result: SAMSegmentationResult, point: {x: number, y: number}) => {
    setSegmentationResult(result);
    setSelectedPoint(point);
    setShowSAMSelector(false);
    setStatus(`Object segmented with ${Math.round(result.confidence * 100)}% confidence`);
    console.log("SAM Segmentation Result:", result);
    console.log("Selected Point:", point);
  };

  // Ìö®Í≥º Ï†ÅÏö©ÌïòÍ∏∞
  const applyEffectToSegmentation = async () => {
    if (!segmentationResult) {
      Alert.alert("Error", "No segmentation result available");
      return;
    }

    try {
      setStatus("Applying effect to segmented object...");
      
      // Ïó¨Í∏∞ÏÑú Ïã§Ï†ú Ìö®Í≥º Ï†ÅÏö© Î°úÏßÅ Íµ¨ÌòÑ
      // ÌòÑÏû¨Îäî placeholder
      console.log("Applying effect with mask:", segmentationResult.maskUri);
      
      // ÏûÑÏãúÎ°ú ÏÑ±Í≥µ Î©îÏãúÏßÄ
      await new Promise(resolve => setTimeout(resolve, 1000));
      setStatus("Effect applied successfully!");
      Alert.alert("Success", "Effect applied to the segmented object!");
      
    } catch (error) {
      setStatus("Failed to apply effect");
      Alert.alert("Error", "Failed to apply effect: " + error);
    }
  };

  // Í∞ùÏ≤¥ Ï∂îÏ†Å
  const trackObject = async () => {
    if (!objectId) {
      Alert.alert("Error", "Please select object first");
      return;
    }

    try {
      setStatus("Tracking object...");

      const results = await ExpoObjectTracker.trackObject(videoUri, objectId);
      setTrackingResults(results);
      setStatus(`Tracking completed - ${results.length} frames`);

      // ÎØ∏Î¶¨Î≥¥Í∏∞ ÌîÑÎ†àÏûÑ ÏÉùÏÑ± (5Í∞ú ÌîÑÎ†àÏûÑ)
      setStatus("Generating preview frames...");
      const frames = await ExpoObjectTracker.generatePreviewFrames(
        videoUri,
        results,
        5
      );
      setPreviewFrames(frames);

      setStatus(`Tracking completed - Ready for effects preview`);
      Alert.alert("Success", `Tracked object in ${results.length} frames`);
      console.log("Tracking results:", results.slice(0, 5)); // Ï≤´ 5ÌîÑÎ†àÏûÑÎßå Î°úÍ∑∏
    } catch (error) {
      setStatus("Tracking failed");
      Alert.alert("Error", "Failed to track object: " + error);
      console.error("Object tracking error:", error);
    }
  };

  // Ìö®Í≥º ÎØ∏Î¶¨Î≥¥Í∏∞
  const previewEffect = async (
    effectConfig: EffectConfig,
    effectName: string
  ) => {
    if (previewFrames.length === 0) {
      Alert.alert("Error", "Please track object first");
      return;
    }

    try {
      setStatus(`Generating ${effectName} preview...`);
      setCurrentPreviewEffect(effectConfig);

      const newPreviewImages: { [key: string]: string } = {};

      // Í∞Å ÎØ∏Î¶¨Î≥¥Í∏∞ ÌîÑÎ†àÏûÑÏóê Ìö®Í≥º Ï†ÅÏö©
      for (const frame of previewFrames) {
        const processedUri = await ExpoObjectTracker.applyEffectToFrame(
          frame.imageUri,
          frame.boundingBox,
          effectConfig
        );
        newPreviewImages[`${effectName}-${frame.frameIndex}`] = processedUri;
      }

      setPreviewImages(newPreviewImages);
      setStatus(`${effectName} preview ready`);
    } catch (error) {
      setStatus("Preview generation failed");
      Alert.alert(
        "Error",
        `Failed to generate ${effectName} preview: ` + error
      );
      console.error("Preview generation error:", error);
    }
  };

  // ÏµúÏ¢Ö ÎπÑÎîîÏò§ Ï†ÄÏû•
  const saveVideo = async () => {
    if (!currentPreviewEffect || trackingResults.length === 0) {
      Alert.alert("Error", "Please preview an effect first");
      return;
    }

    try {
      setStatus("Saving video with effects...");

      const processedUri = await ExpoObjectTracker.applyEffectToTrackedObject(
        videoUri,
        trackingResults,
        currentPreviewEffect
      );

      setProcessedVideoUri(processedUri);
      setStatus("Video saved successfully");

      Alert.alert("Success", `Video saved at: ${processedUri}`);
      console.log("Processed video URI:", processedUri);
    } catch (error) {
      setStatus("Video save failed");
      Alert.alert("Error", "Failed to save video: " + error);
      console.error("Video save error:", error);
    }
  };

  // Í∞Å Ìö®Í≥ºÎ≥Ñ ÎØ∏Î¶¨Î≥¥Í∏∞ Ìï∏Îì§Îü¨Îì§
  const previewBlurEffect = () =>
    previewEffect({ type: "blur", intensity: 8 }, "blur");
  const previewMosaicEffect = () =>
    previewEffect({ type: "mosaic", blockSize: 15 }, "mosaic");
  const previewEmojiEffect = () =>
    previewEffect({ type: "emoji", emoji: "üòé", scale: 1.5 }, "emoji");
  const previewColorEffect = () =>
    previewEffect({ type: "color", color: "#FF0000", opacity: 0.7 }, "color");

  // SAM Í∞ùÏ≤¥ ÏÑ†ÌÉùÍ∏∞ ÌëúÏãú
  if (showSAMSelector && thumbnailUri) {
    return (
      <SafeAreaView style={styles.container}>
        <SAMObjectSelector
          thumbnailUri={thumbnailUri}
          videoUri={videoUri}
          imageWidth={thumbnailWidth}
          imageHeight={thumbnailHeight}
          onObjectSegmented={onObjectSegmented}
          onCancel={() => setShowSAMSelector(false)}
        />
      </SafeAreaView>
    );
  }

  return (
    <SafeAreaView style={styles.container}>
      <ScrollView style={styles.container}>
        <Text style={styles.header}>ü§ñ AI Í∞ùÏ≤¥ ÏÑ∏Í∑∏Î®ºÌÖåÏù¥ÏÖò & Î∏îÎü¨</Text>

        <Group name="Status">
          <Text style={styles.statusText}>{status}</Text>
        </Group>

        <Group name="1. ÎπÑÎîîÏò§ ÏÑ†ÌÉù">
          <View style={styles.effectButtonsContainer}>
            <Button 
              title="Í∞§Îü¨Î¶¨ÏóêÏÑú ÏÑ†ÌÉù" 
              onPress={selectVideo} 
              disabled={!modelLoaded}
            />
            <Button 
              title="ÌÖåÏä§Ìä∏ ÎπÑÎîîÏò§ ÏÇ¨Ïö©" 
              onPress={loadTestVideo} 
              disabled={!modelLoaded}
            />
          </View>
          {!modelLoaded ? (
            <Text style={styles.infoText}>SAM Î™®Îç∏ Ï¥àÍ∏∞Ìôî Ï§ë...</Text>
          ) : videoUri ? (
            <Text style={styles.infoText}>‚úÖ ÎπÑÎîîÏò§ Î°úÎìúÎê®</Text>
          ) : null}
        </Group>

        <Group name="2. AI Í∞ùÏ≤¥ ÏÑ†ÌÉù">
          <Button
            title="üéØ Í∞ùÏ≤¥ ÌÑ∞ÏπòÌï¥ÏÑú ÏÑ†ÌÉùÌïòÍ∏∞"
            onPress={showSAMObjectSelection}
            disabled={!thumbnailUri}
          />
          <Text style={styles.hintText}>
            üí° Segment Anything AIÍ∞Ä ÌÑ∞ÏπòÌïú Í∞ùÏ≤¥Î•º Ï†ïÎ∞ÄÌïòÍ≤å Ï∞æÏäµÎãàÎã§
          </Text>
          
          {segmentationResult ? (
            <View>
              <Text style={styles.infoText}>‚úÖ Í∞ùÏ≤¥ ÏÑ∏Í∑∏Î®ºÌÖåÏù¥ÏÖò ÏôÑÎ£å!</Text>
              <Text style={styles.resultText}>
                Ïã†Î¢∞ÎèÑ: {Math.round(segmentationResult.confidence * 100)}%
              </Text>
              <Text style={styles.resultText}>
                ÏÑ†ÌÉùÎêú ÏúÑÏπò: ({selectedPoint?.x.toFixed(0)}, {selectedPoint?.y.toFixed(0)})
              </Text>
            </View>
          ) : null}
        </Group>

        {segmentationResult && (
          <Group name="3. Ìö®Í≥º Ï†ÅÏö©">
            <View style={styles.effectButtonsContainer}>
              <Button
                title="üåÄ Î∏îÎü¨ Ìö®Í≥º"
                onPress={applyEffectToSegmentation}
              />
              <Button
                title="üî≥ Î™®ÏûêÏù¥ÌÅ¨"
                onPress={applyEffectToSegmentation}
              />
            </View>
            <Text style={styles.hintText}>
              ÏÑ†ÌÉùÎêú Í∞ùÏ≤¥ ÏòÅÏó≠ÏóêÎßå Ìö®Í≥ºÍ∞Ä Ï†ïÎ∞ÄÌïòÍ≤å Ï†ÅÏö©Îê©ÎãàÎã§
            </Text>
          </Group>
        )}

        {processedVideoUri && (
          <Group name="Í≤∞Í≥º">
            <Text style={styles.infoText}>‚úÖ Ìö®Í≥º Ï†ÅÏö© ÏôÑÎ£å!</Text>
            <Text style={styles.resultText}>
              Ï≤òÎ¶¨Îêú ÎπÑÎîîÏò§: {processedVideoUri}
            </Text>
          </Group>
        )}
      </ScrollView>
    </SafeAreaView>
  );
}

function Group(props: { name: string; children: React.ReactNode }) {
  return (
    <View style={styles.group}>
      <Text style={styles.groupHeader}>{props.name}</Text>
      {props.children}
    </View>
  );
}

const styles = StyleSheet.create({
  header: {
    fontSize: 24,
    fontWeight: "bold" as const,
    margin: 20,
    textAlign: "center" as const,
    color: "#333",
  },
  groupHeader: {
    fontSize: 18,
    fontWeight: "bold" as const,
    marginBottom: 15,
    color: "#444",
  },
  group: {
    margin: 15,
    backgroundColor: "#fff",
    borderRadius: 12,
    padding: 20,
    shadowColor: "#000",
    shadowOffset: { width: 0, height: 2 },
    shadowOpacity: 0.1,
    shadowRadius: 4,
    elevation: 3,
  },
  container: {
    flex: 1,
    backgroundColor: "#f5f5f5",
  },
  statusText: {
    fontSize: 16,
    fontWeight: "500" as const,
    color: "#007AFF",
    textAlign: "center" as const,
  },
  infoText: {
    fontSize: 14,
    color: "#28a745",
    marginTop: 10,
    textAlign: "center" as const,
  },
  resultText: {
    fontSize: 12,
    color: "#666",
    marginTop: 5,
  },
  selectorContainer: {
    flex: 1,
    padding: 20,
    alignItems: "center" as const,
  },
  instructionText: {
    fontSize: 16,
    color: "#666",
    textAlign: "center" as const,
    marginBottom: 20,
  },
  buttonContainer: {
    marginTop: 20,
    width: "100%",
  },
  effectButtonsContainer: {
    flexDirection: "row" as const,
    justifyContent: "space-around",
    marginBottom: 10,
  },
  previewContainer: {
    marginTop: 15,
    padding: 10,
    backgroundColor: "#f8f8f8",
    borderRadius: 8,
  },
  previewTitle: {
    fontSize: 14,
    fontWeight: "600" as const,
    marginBottom: 10,
    color: "#333",
  },
  previewImage: {
    width: 120,
    height: 90,
    marginRight: 10,
    borderRadius: 6,
    borderWidth: 1,
    borderColor: "#ddd",
  },
  previewImageContainer: {
    marginBottom: 20,
    borderRadius: 8,
    overflow: "hidden",
    borderWidth: 2,
    borderColor: "#4CAF50",
  },
  detectionInfo: {
    backgroundColor: "white",
    padding: 15,
    borderRadius: 8,
    marginBottom: 20,
    alignItems: "center" as const,
    shadowColor: "#000",
    shadowOffset: { width: 0, height: 1 },
    shadowOpacity: 0.2,
    shadowRadius: 2,
    elevation: 2,
  },
  detectionText: {
    fontSize: 14,
    color: "#333",
    marginBottom: 5,
    fontWeight: "500" as const,
  },
  confirmButtonContainer: {
    flexDirection: "row" as const,
    justifyContent: "space-around",
    width: "100%",
    maxWidth: 300,
  },
  retryButton: {
    backgroundColor: "#FF9800",
  },
  button: {
    paddingVertical: 12,
    paddingHorizontal: 20,
    borderRadius: 8,
    minWidth: 80,
    alignItems: "center" as const,
    margin: 5,
  },
  buttonText: {
    color: "white",
    fontSize: 16,
    fontWeight: "600" as const,
  },
  confirmButton: {
    backgroundColor: "#4CAF50",
  },
  hintText: {
    fontSize: 12,
    color: "#6c757d",
    textAlign: "center" as const,
    marginTop: 8,
    fontStyle: "italic" as const,
  },
});
